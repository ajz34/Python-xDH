{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MP2 二阶梯度：微分 Z-Vector 方程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这份文档将会从 MP2 一阶梯度公式出发，推导二阶梯度的表达式并程序化．Cammi, R. et al TCA 2004, 111, 66-77 (doi: 10.1007/s00214-003-0521-8) 提供的非常好的思路；但这篇文章使用到稍微复杂的轨道旋转，而轨道旋转不太适合使用矩阵的数值导数直接验证，一些变量也会相应地不太直观．因此，我们将会使用 Canonical HF 的轨道重新描述微分 Z-Vector 方程．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyscf import scf, gto, lib, grad, hessian, dft, mp\n",
    "import pyscf.hessian.rks\n",
    "import pyscf.grad.rks\n",
    "from functools import partial\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utilities import val_from_fchk, NumericDiff\n",
    "from hessian import HFHelper, GGAHelper\n",
    "\n",
    "np.einsum = partial(np.einsum, optimize=[\"greedy\", 1024 ** 3 * 2 / 8])\n",
    "np.einsum_path = partial(np.einsum_path, optimize=[\"greedy\", 1024 ** 3 * 2 / 8])\n",
    "np.set_printoptions(6, linewidth=150, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol = gto.Mole()\n",
    "mol.atom = \"\"\"\n",
    "O  0.0  0.0  0.0\n",
    "O  0.0  0.0  1.5\n",
    "H  1.5  0.0  0.0\n",
    "H  0.0  0.7  1.5\n",
    "\"\"\"\n",
    "mol.basis = \"6-31G\"\n",
    "mol.verbose = 0\n",
    "mol.build()\n",
    "\n",
    "nmo = nao = mol.nao\n",
    "natm = mol.natm\n",
    "nocc = mol.nelec[0]\n",
    "nvir = nmo - nocc\n",
    "so = slice(0, nocc)\n",
    "sv = slice(nocc, nmo)\n",
    "sa = slice(0, nmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文档定义所用变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/zyzhu/Git-Repo/Python-xDH/pyxdh/hessian/hf_helper.py:366: UserWarning: U_1: Generating total U matrix should be considered as numerical unstable!\n",
      "  warnings.warn(\"U_1: Generating total U matrix should be considered as numerical unstable!\")\n",
      "/share/home/zyzhu/Git-Repo/Python-xDH/pyxdh/hessian/hf_helper.py:229: UserWarning: eri0_mo: ERI AO -> MO is quite expensive!\n",
      "  warnings.warn(\"eri0_mo: ERI AO -> MO is quite expensive!\")\n",
      "/share/home/zyzhu/Git-Repo/Python-xDH/pyxdh/hessian/hf_helper.py:222: UserWarning: eri0_ao: ERI should not be stored in memory! Consider J/K engines!\n",
      "  warnings.warn(\"eri0_ao: ERI should not be stored in memory! Consider J/K engines!\")\n",
      "/share/home/zyzhu/Git-Repo/Python-xDH/pyxdh/hessian/hf_helper.py:279: UserWarning: eri1_mo: 4-idx tensor ERI should be not used!\n",
      "  warnings.warn(\"eri1_mo: 4-idx tensor ERI should be not used!\")\n",
      "/share/home/zyzhu/Git-Repo/Python-xDH/pyxdh/hessian/hf_helper.py:272: UserWarning: eri1_ao: 4-idx tensor ERI should be not used!\n",
      "  warnings.warn(\"eri1_ao: 4-idx tensor ERI should be not used!\")\n",
      "/share/home/zyzhu/Git-Repo/Python-xDH/pyxdh/hessian/hf_helper.py:317: UserWarning: eri2_mo: 4-idx tensor ERI should be not used!\n",
      "  warnings.warn(\"eri2_mo: 4-idx tensor ERI should be not used!\")\n",
      "/share/home/zyzhu/Git-Repo/Python-xDH/pyxdh/hessian/hf_helper.py:310: UserWarning: eri2_ao: 4-idx tensor ERI should be not used!\n",
      "  warnings.warn(\"eri2_ao: 4-idx tensor ERI should be not used!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hessian.hf_helper.HFHelper at 0x2b07086d0cf8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use U_1 in this document, but no U_2\n",
    "# We still using MO basis ERI\n",
    "# Pre-generate some code here will make later work quicker\n",
    "# But these operations are numerical-unstable or memory consuming\n",
    "hfh = HFHelper(mol)\n",
    "hfh.U_1\n",
    "hfh.eri0_mo\n",
    "hfh.eri1_mo\n",
    "hfh.eri2_mo\n",
    "hfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, eo, ev = hfh.e, hfh.eo, hfh.ev\n",
    "C, Co, Cv = hfh.C, hfh.Co, hfh.Cv\n",
    "D = hfh.D\n",
    "eri0_mo = hfh.eri0_mo\n",
    "eri1_mo = hfh.eri1_mo\n",
    "eri2_mo = hfh.eri2_mo\n",
    "\n",
    "F_1_mo = hfh.F_1_mo\n",
    "S_1_mo = hfh.S_1_mo\n",
    "U_1_vo = hfh.U_1_vo\n",
    "U_1 = hfh.U_1  # Only for verify\n",
    "B_1 = hfh.B_1\n",
    "Ax0_Core = hfh.Ax0_Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MP2 Hessian 参考值如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_array = val_from_fchk(\"Cartesian Force Constants\", \"include/mp2_hess/mp2_hess.fchk\")\n",
    "d_hess = natm * 3\n",
    "hess_mp2_gaussian = np.zeros((d_hess, d_hess))\n",
    "p = 0\n",
    "for d1 in range(d_hess):\n",
    "    for d2 in range(d1 + 1):\n",
    "        hess_mp2_gaussian[d1][d2] = hess_mp2_gaussian[d2][d1] = g_array[p]\n",
    "        p += 1\n",
    "hess_mp2_gaussian = hess_mp2_gaussian.reshape((natm, 3, natm, 3)).swapaxes(1, 2)\n",
    "hess_mp2_ref = hess_mp2_gaussian - hfh.scf_hess.kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MP2 一阶梯度：回顾与变量定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MP2 PySCF 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.102293,  0.014371,  0.031588],\n",
       "       [ 0.008573,  0.75439 , -0.009366],\n",
       "       [ 0.087807,  0.00276 ,  0.014487],\n",
       "       [ 0.005914, -0.77152 , -0.036708]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfh.scf_grad.kernel()\n",
    "mp2_eng = mp.MP2(hfh.scf_eng)\n",
    "mp2_eng.kernel()[0]\n",
    "mp2_grad = grad.mp2.Gradients(mp2_eng)\n",
    "mp2_grad.kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "双电子积分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_mo = eri0_mo\n",
    "G_mo = 2 * g_mo - g_mo.swapaxes(-1, -3)\n",
    "g_iajb = g_mo[so, sv, so, sv]\n",
    "G_iajb = G_mo[so, sv, so, sv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "双电子积分的 Skeleton 梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_g_mo = eri1_mo\n",
    "pd_G_mo = 2 * pd_g_mo - pd_g_mo.swapaxes(-1, -3)\n",
    "pd_g_iajb = pd_g_mo[:, :, so, sv, so, sv]\n",
    "pd_G_iajb = pd_G_mo[:, :, so, sv, so, sv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MP2 Amplitude 与能量计算相关表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/zyzhu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \n",
      "/share/home/zyzhu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in subtract\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Define t, g\n",
    "D_iajb = lib.direct_sum(\"i - a + j - b\", eo, ev, eo, ev)\n",
    "t_iajb = g_iajb / D_iajb\n",
    "T_iajb = 2 * t_iajb - t_iajb.swapaxes(-1, -3)\n",
    "D_mo = lib.direct_sum(\"i - a + j - b\", e, e, e, e)\n",
    "t_mo = g_mo / D_mo\n",
    "T_mo = 2 * t_mo - t_mo.swapaxes(-1, -3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证 MP2 能量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose((t_iajb * T_iajb * D_iajb).sum(), mp2_eng.e_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "弛豫密度、加权密度相关量定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_r = np.zeros((nmo, nmo))\n",
    "D_r[so, so] += - 2 * np.einsum(\"iakb, jakb -> ij\", T_iajb, t_iajb)\n",
    "D_r[sv, sv] += 2 * np.einsum(\"iajc, ibjc -> ab\", T_iajb, t_iajb)\n",
    "\n",
    "L = np.zeros((nvir, nocc))\n",
    "L += Ax0_Core(sv, so, sa, sa)(D_r)\n",
    "L -= 4 * np.einsum(\"jakb, ijbk -> ai\", T_iajb, g_mo[so, so, sv, so])\n",
    "L += 4 * np.einsum(\"ibjc, abjc -> ai\", T_iajb, g_mo[sv, sv, so, sv])\n",
    "\n",
    "D_r[sv, so] = scf.cphf.solve(Ax0_Core(sv, so, sv, so), e, hfh.mo_occ, L, max_cycle=100, tol=1e-13)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W[I] - Correct with s1-im1 term in PySCF\n",
    "D_WI = np.zeros((nmo, nmo))\n",
    "D_WI[so, so] = - 2 * np.einsum(\"iakb, jakb -> ij\", T_iajb, g_mo[so, sv, so, sv])\n",
    "D_WI[sv, sv] = - 2 * np.einsum(\"iajc, ibjc -> ab\", T_iajb, g_mo[so, sv, so, sv])\n",
    "D_WI[sv, so] = - 4 * np.einsum(\"jakb, ijbk -> ai\", T_iajb, g_mo[so, so, sv, so])\n",
    "\n",
    "# W[II] - Correct with s1-zeta term in PySCF\n",
    "# Note that zeta in PySCF includes HF energy weighted density rdm1e\n",
    "# The need of scaler 1 in D_WII[sv, so] is that Aikens use doubled P\n",
    "D_WII = np.zeros((nmo, nmo))\n",
    "D_WII[so, so] = - 0.5 * D_r[so, so] * lib.direct_sum(\"i + j -> ij\", eo, eo)\n",
    "D_WII[sv, sv] = - 0.5 * D_r[sv, sv] * lib.direct_sum(\"a + b -> ab\", ev, ev)\n",
    "D_WII[sv, so] = - D_r[sv, so] * eo\n",
    "\n",
    "# W[III] - Correct with s1-vhf_s1occ term in PySCF\n",
    "D_WIII = np.zeros((nmo, nmo))\n",
    "D_WIII[so, so] = - 0.5 * Ax0_Core(so, so, sa, sa)(D_r)\n",
    "\n",
    "# Summation\n",
    "D_W = D_WI + D_WII + D_WIII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证 MP2 一阶梯度，这里采用的一阶梯度公式是\n",
    "\n",
    "$$\n",
    "E_\\mathrm{elec}^{\\mathrm{MP2}, A_t} = D_{pq}^\\mathrm{MP2} F_{pq}^{A_t} + W_{pq}^\\mathrm{MP2} S_{pq}^{A_t} + 2 T_{ij}^{ab} (\\partial_{A_t} g_{ij}^{ab})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(\n",
    "    + (D_r * F_1_mo).sum(axis=(-1, -2))\n",
    "    + (D_W * S_1_mo).sum(axis=(-1, -2))\n",
    "    + (2 * T_iajb * pd_g_iajb).sum(axis=(-1, -2, -3, -4)),\n",
    "    mp2_grad.de - hfh.scf_grad.de\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MP2 二阶梯度：微分 Z-Vector 方程的不安全实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过微分 Z-Vector 方程求解 MP2 Hessian 的过程，实际上仅仅是对使用弛豫密度、加权密度等表示的 MP2 梯度，直接进行再一次求导．如果 MP2 一阶梯度表示为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E_\\mathrm{elec}^{\\mathrm{MP2}, A_t} = (\\frac{\\partial}{\\partial A_t} T_{ij}^{ab}) t_{ij}^{ab} D_{ij}^{ab} + T_{ij}^{ab} (\\frac{\\partial}{\\partial A_t} t_{ij}^{ab}) D_{ij}^{ab} + T_{ij}^{ab} t_{ij}^{ab} (\\frac{\\partial}{\\partial A_t} D_{ij}^{ab})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么 MP2 的二阶梯度可以表示为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "E_\\mathrm{elec}^{\\mathrm{MP2}, A_t B_s} =\n",
    "&+ D_{pq}^\\mathrm{MP2} (\\frac{\\partial}{\\partial B_s} F_{pq}^{A_t}) + W_{pq}^\\mathrm{MP2} (\\frac{\\partial}{\\partial B_s} S_{pq}^{A_t}) \\\\\n",
    "&+ (\\frac{\\partial}{\\partial B_s} D_{pq}^\\mathrm{MP2}) F_{pq}^{A_t} + (\\frac{\\partial}{\\partial B_s} W_{pq}^\\mathrm{MP2}) S_{pq}^{A_t} \\\\\n",
    "&+ 2 (\\frac{\\partial}{\\partial B_s} T_{ij}^{ab}) (\\partial_{A_t} g_{ij}^{ab}) + 2 T_{ij}^{ab} (\\frac{\\partial}{\\partial B_s} \\partial_{A_t} g_{ij}^{ab})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们简单地称这些项是 MP2 Hessian 的六个贡献项．其中，在现在的推导框架下，第 1, 2, 5, 6 很快可以被求出．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一贡献项 $D_{pq}^\\mathrm{MP2} (\\frac{\\partial}{\\partial B_s} F_{pq}^{A_t})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一项的难点仅仅在于求取 Fock 一阶 Skeleton 梯度的一阶全导数．我们通过下面的程序验证我们可以生成正确的 `pdA_F_1_mo` $\\frac{\\partial}{\\partial B_s} F_{pq}^{A_t}$："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_F_1_mo(mol):\n",
    "    return HFHelper(mol).F_1_mo\n",
    "F_1_mo_diff = NumericDiff(mol, mol_to_F_1_mo, deriv=2, symm=False).get_numdif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdA_F_1_mo = (\n",
    "    + hfh.F_2_mo\n",
    "    + np.einsum(\"Atpm, Bsmq -> ABtspq\", hfh.F_1_mo, U_1)\n",
    "    + np.einsum(\"Atmq, Bsmp -> ABtspq\", hfh.F_1_mo, U_1)\n",
    "    + hfh.Ax1_Core(sa, sa, sa, so)(U_1[:, :, :, so])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(abs(pdA_F_1_mo - F_1_mo_diff).ravel(),\n",
    "         bins=np.logspace(np.log10(1e-10),np.log10(1e-3), 50))\n",
    "plt.gca().set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，第一贡献项 `hess_mp2_unsafe_contrib1` $D_{pq}^\\mathrm{MP2} (\\frac{\\partial}{\\partial B_s} F_{pq}^{A_t})$ 可以非常直观地写出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_mp2_unsafe_contrib1 = np.einsum(\"pq, ABtspq -> ABts\", D_r, pdA_F_1_mo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二贡献项 $W_{pq}^\\mathrm{MP2} (\\frac{\\partial}{\\partial B_s} S_{pq}^{A_t})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一项的难点也仅仅在于求取 `pdA_S_1_mo` $(\\frac{\\partial}{\\partial B_s} S_{pq}^{A_t})$．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol_to_S_1_mo(mol):\n",
    "    return HFHelper(mol).S_1_mo\n",
    "S_1_mo_diff = NumericDiff(mol, mol_to_S_1_mo, deriv=2, symm=False).get_numdif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdA_S_1_mo = (\n",
    "    + hfh.S_2_mo\n",
    "    + np.einsum(\"Atpm, Bsmq -> ABtspq\", hfh.S_1_mo, U_1)\n",
    "    + np.einsum(\"Atmq, Bsmp -> ABtspq\", hfh.S_1_mo, U_1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(abs(pdA_S_1_mo - S_1_mo_diff).ravel(),\n",
    "         bins=np.logspace(np.log10(1e-10),np.log10(1e-3), 50))\n",
    "plt.gca().set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二贡献项 `hess_mp2_unsafe_contrib2` $W_{pq}^\\mathrm{MP2} (\\frac{\\partial}{\\partial B_s} S_{pq}^{A_t})$ 也可以非常直观地写出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_mp2_unsafe_contrib2 = np.einsum(\"pq, ABtspq -> ABts\", D_W, pdA_S_1_mo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第五、六贡献项 $2 (\\frac{\\partial}{\\partial B_s} T_{ij}^{ab}) (\\partial_{A_t} g_{ij}^{ab}) + 2 T_{ij}^{ab} (\\frac{\\partial}{\\partial B_s} \\partial_{A_t} g_{ij}^{ab})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在求取第五、第六贡献项前，我们需要简单回顾一下暴力求解 MP2 梯度时所使用的生成类似于 $\\frac{\\partial}{\\partial A_t} g_{ij}^{ab}$ 的方式．这种方式尽管非常占用内存资源，但在实践中很可能无法避免，至少如果不打算牺牲太多代码可读性时应是不可避免的．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(注意这个文档块的 $i, a, j, b$ 在代码中可能代表全轨道)\n",
    "\n",
    "* `pd_g_mo`:  $\\partial_{A_t} g_{ij}^{ab} = (ia|jb)^{A_t}$\n",
    "\n",
    "* `pdU_g_mo`: $\\partial_{A_t}^\\mathrm{U} g_{ij}^{ab} = g_{pj}^{ab} U_{pi}^\\mathrm{A_t} + g_{ip}^{ab} U_{pj}^\\mathrm{A_t} + g_{ij}^{pb} U_{pa}^\\mathrm{A_t} + g_{ij}^{ap} U_{pb}^\\mathrm{A_t}$\n",
    "\n",
    "* `pdA_g_mo`: $\\frac{\\partial}{\\partial A_t} g_{ij}^{ab} = \\partial_{A_t} g_{ij}^{ab} + \\partial_{A_t}^\\mathrm{U} g_{ij}^{ab}$\n",
    "\n",
    "* `pdA_G_mo`: $\\frac{\\partial}{\\partial A_t} \\tilde g_{ij}^{ab} = 2 \\frac{\\partial}{\\partial A_t} g_{ij}^{ab} - \\frac{\\partial}{\\partial A_t} g_{ij}^{ba}$\n",
    "\n",
    "* `pdA_g_iajb`: `pdA_g_mo` 的分割\n",
    "\n",
    "* `pdA_G_iajb`: `pdA_G_mo` 的分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_g_mo = eri1_mo\n",
    "pdU_g_mo = (\n",
    "    + np.einsum(\"pjkl, Atpi -> Atijkl\", g_mo, U_1)\n",
    "    + np.einsum(\"ipkl, Atpj -> Atijkl\", g_mo, U_1)\n",
    "    + np.einsum(\"ijpl, Atpk -> Atijkl\", g_mo, U_1)\n",
    "    + np.einsum(\"ijkp, Atpl -> Atijkl\", g_mo, U_1)\n",
    ")\n",
    "pdA_g_mo = pd_g_mo + pdU_g_mo\n",
    "pdA_G_mo = 2 * pdA_g_mo - pdA_g_mo.swapaxes(-1, -3)\n",
    "\n",
    "pdA_g_iajb = pdA_g_mo[:, :, so, sv, so, sv]\n",
    "pdA_G_iajb = pdA_G_mo[:, :, so, sv, so, sv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `pd_pd_g_mo`: $\\partial_{B_s} \\partial_{A_t} g_{ij}^{ab} = (ia|jb)^{A_t B_s}$\n",
    "\n",
    "* `pdU_pd_g_mo`: $\\partial_{B_s}^\\mathrm{U} \\partial_{A_t} g_{ij}^{ab} = \\partial_{A_t} g_{pj}^{ab} U_{pi}^\\mathrm{B_s} + \\partial_{A_t} g_{ip}^{ab} U_{pj}^\\mathrm{B_s} + \\partial_{A_t} g_{ij}^{pb} U_{pa}^\\mathrm{B_s} + \\partial_{A_t} g_{ij}^{ap} U_{pb}^\\mathrm{B_s}$\n",
    "\n",
    "* `pdA_pd_g_mo`: $\\frac{\\partial}{\\partial B_s} \\partial_{A_t} g_{ij}^{ab} = \\partial_{B_s} \\partial_{A_t} g_{ij}^{ab} + \\partial_{B_s}^\\mathrm{U} \\partial_{A_t} g_{ij}^{ab}$\n",
    "\n",
    "* `pdA_pd_g_iajb`: `pdA_pd_g_mo` 的分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_pd_g_mo = eri2_mo\n",
    "pdU_pd_g_mo = (\n",
    "    # pd on g, U matrix on B\n",
    "    + np.einsum(\"Atpjkl, Bspi -> ABtsijkl\", pd_g_mo, U_1)\n",
    "    + np.einsum(\"Atipkl, Bspj -> ABtsijkl\", pd_g_mo, U_1)\n",
    "    + np.einsum(\"Atijpl, Bspk -> ABtsijkl\", pd_g_mo, U_1)\n",
    "    + np.einsum(\"Atijkp, Bspl -> ABtsijkl\", pd_g_mo, U_1)\n",
    ")\n",
    "pdA_pd_g_mo = pd_pd_g_mo + pdU_pd_g_mo\n",
    "pdA_pd_g_iajb = pdA_pd_g_mo[:, :, :, :, so, sv, so, sv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `e_1`: $\\varepsilon_p^{A_t} = \\frac{\\partial}{\\partial A_t} \\varepsilon = B_{pp}^{A_t} + A_{pp, bj} U_{bj}^{A_t}$\n",
    "\n",
    "* `eo_1`, `ev_1`: `e_1` 的分割\n",
    "\n",
    "* `pdA_D_iajb`: $\\frac{\\partial}{\\partial A_t} D_{ij}^{ab} = \\varepsilon_i^{A_t} - \\varepsilon_a^{A_t} + \\varepsilon_j^{A_t} - \\varepsilon_b^{A_t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_1 = (B_1 + Ax0_Core(sa, sa, sv, so)(U_1_vo)).diagonal(0, -1, -2)\n",
    "eo_1, ev_1 = e_1[:, :, so], e_1[:, :, sv]\n",
    "\n",
    "pdA_D_iajb = (\n",
    "    + eo_1[:, :, :, None, None, None]\n",
    "    - ev_1[:, :, None, :, None, None]\n",
    "    + eo_1[:, :, None, None, :, None]\n",
    "    - ev_1[:, :, None, None, None, :]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `pdA_t_iajb`: $\\frac{\\partial}{\\partial A_t} t_{ij}^{ab} = (\\frac{\\partial}{\\partial A_t} g_{ij}^{ab}) (D_{ij}^{ab})^{-1} - t_{ij}^{ab} (D_{ij}^{ab})^{-1} \\frac{\\partial}{\\partial A_t} D_{ij}^{ab}$\n",
    "\n",
    "* `pdA_T_iajb`: $\\frac{\\partial}{\\partial A_t} T_{ij}^{ab} = 2 \\frac{\\partial}{\\partial A_t} t_{ij}^{ab} - \\frac{\\partial}{\\partial A_t} t_{ij}^{ba}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdA_t_iajb = (\n",
    "    + pdA_g_iajb / D_iajb\n",
    "    - np.einsum(\"Atiajb, iajb, iajb -> Atiajb\", pdA_D_iajb, t_iajb, 1 / D_iajb)\n",
    ")\n",
    "pdA_T_iajb = 2 * pdA_t_iajb - pdA_t_iajb.swapaxes(-1, -3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以预先验证 MP2 能量 $E_\\mathrm{elec}^\\mathrm{MP2} = T_{ij}^{ab} t_{ij}^{ab} D_{ij}^{ab}$ 的一阶梯度在这种表示下是成立的："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E_\\mathrm{elec}^{\\mathrm{MP2}, A_t} = (\\frac{\\partial}{\\partial A_t} T_{ij}^{ab}) t_{ij}^{ab} D_{ij}^{ab} + T_{ij}^{ab} (\\frac{\\partial}{\\partial A_t} t_{ij}^{ab}) D_{ij}^{ab} + T_{ij}^{ab} t_{ij}^{ab} (\\frac{\\partial}{\\partial A_t} D_{ij}^{ab})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0., -0.],\n",
       "       [-0., -0., -0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    + np.einsum(\"Atiajb, iajb, iajb -> At\", pdA_t_iajb, T_iajb, D_iajb)\n",
    "    + np.einsum(\"iajb, Atiajb, iajb -> At\", t_iajb, pdA_T_iajb, D_iajb)\n",
    "    + np.einsum(\"iajb, iajb, Atiajb -> At\", t_iajb, T_iajb, pdA_D_iajb)\n",
    ") - (mp2_grad.de - hfh.scf_grad.de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以验证 MP2 能量 $E_\\mathrm{elec}^\\mathrm{MP2} = T_{ij}^{ab} g_{ij}^{ab}$ 所表示的一阶梯度："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E_\\mathrm{elec}^{\\mathrm{MP2}, A_t} = (\\frac{\\partial}{\\partial A_t} T_{ij}^{ab}) g_{ij}^{ab} + T_{ij}^{ab} (\\frac{\\partial}{\\partial A_t} g_{ij}^{ab})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0., -0.],\n",
       "       [-0., -0., -0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    + np.einsum(\"Atiajb, iajb -> At\", pdA_T_iajb, g_iajb)\n",
    "    + np.einsum(\"iajb, Atiajb -> At\", T_iajb, pdA_g_iajb)\n",
    ") - (mp2_grad.de - hfh.scf_grad.de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由此，第 5, 6 贡献项 `hess_mp2_unsafe_contrib5_6` $2 (\\frac{\\partial}{\\partial B_s} T_{ij}^{ab}) (\\partial_{A_t} g_{ij}^{ab}) + 2 T_{ij}^{ab} (\\frac{\\partial}{\\partial B_s} \\partial_{A_t} g_{ij}^{ab})$ 已经是显然得到的了："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_mp2_unsafe_contrib5_6 = (\n",
    "    + 2 * np.einsum(\"Bsiajb, Atiajb -> ABts\", pdA_T_iajb, pd_g_iajb)\n",
    "    + 2 * np.einsum(\"iajb, ABtsiajb -> ABts\", T_iajb, pdA_pd_g_iajb)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 弛豫密度全导数 $\\frac{\\partial}{\\partial A_t} D_{pq}^\\mathrm{MP2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了获得第 3, 4 贡献项，我们需要求取 MP2 弛豫密度的梯度．这是 Z-Vector 梯度推导过程的重要中间过程，也是公式理解和程序调试最为困难的部分．\n",
    "\n",
    "我们在这份文档末尾会指出，弛豫密度中非占-占据部分的全导数未必需要求取．但在理解问题的过程中，我们不妨可以先求取这部分弛豫密度的全导数．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先挑软的柿子捏．弛豫密度分为三部分，其中的占据-占据与非占-非占部分的导数较为方便；但非占-占据部分的导数比较复杂．我们的程序中，占据-非占部分始终是零．那么我们先把占据-占据和非占-非占的梯度求取出来．回顾占据-占据与非占-非占|弛豫密度定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Aikens, 177, 178)\n",
    "\n",
    "\\begin{align}\n",
    "D_{ij}^\\mathrm{MP2} &= - 2 T_{ik}^{ab} t_{jk}^{ab} \\\\\n",
    "D_{ab}^\\mathrm{MP2} &= 2 T_{ij}^{ac} t_{ij}^{bc}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，这部分的 `pdA_D_r` 二阶梯度非常容易获得："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `pdA_D_r[:, :, so, so]`: $\\frac{\\partial}{\\partial A_t} D_{ij}^\\mathrm{MP2} = -2 (\\frac{\\partial}{\\partial A_t} T_{ij}^{ab}) t_{ij}^{ab} - 2 T_{ij}^{ab} (\\frac{\\partial}{\\partial A_t} t_{ij}^{ab})$\n",
    "\n",
    "* `pdA_D_r[:, :, sv, sv]`: $\\frac{\\partial}{\\partial A_t} D_{ab}^\\mathrm{MP2} = 2 (\\frac{\\partial}{\\partial A_t} T_{ij}^{ac}) t_{ij}^{bc} + 2 T_{ij}^{bc} (\\frac{\\partial}{\\partial A_t} t_{ij}^{bc})$\n",
    "\n",
    "* `D_r_oo`, `D_r_vv`, `D_r_vo`, `pdA_D_r_oo`, `pdA_D_r_vv`: 对应弛豫密度或其导数的分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdA_D_r = np.zeros((natm, 3, nmo, nmo))\n",
    "pdA_D_r[:, :, so, so] -= 2 * np.einsum(\"iakb, Atjakb -> Atij\", T_iajb, pdA_t_iajb)\n",
    "pdA_D_r[:, :, sv, sv] += 2 * np.einsum(\"iajc, Atibjc -> Atab\", T_iajb, pdA_t_iajb)\n",
    "pdA_D_r[:, :, so, so] -= 2 * np.einsum(\"Atiakb, jakb -> Atij\", pdA_T_iajb, t_iajb)\n",
    "pdA_D_r[:, :, sv, sv] += 2 * np.einsum(\"Atiajc, ibjc -> Atab\", pdA_T_iajb, t_iajb)\n",
    "\n",
    "D_r_oo = D_r[so, so]\n",
    "D_r_vv = D_r[sv, sv]\n",
    "D_r_vo = D_r[sv, so]\n",
    "pdA_D_r_oo = pdA_D_r[:, :, so, so]\n",
    "pdA_D_r_vv = pdA_D_r[:, :, sv, sv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随后我们求取 Lagrangian 项的全导数．我们回顾 Lagrangian 项的定义："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Aikens, 159)\n",
    "\n",
    "\\begin{align}\n",
    "L_{ai} =& A_{ai, kl} D_{kl}^\\mathrm{MP2} + A_{ai, bc} D_{bc}^\\mathrm{MP2} \\\\\n",
    "&- 4 T_{jk}^{ab} (ij|bk) + 4 T_{ij}^{bc} (ab|jc)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这四项 Lagrangian 项的导数稍有些复杂．我们使用 `RHS` 先储存 Lagrangian 项导数 $\\frac{\\partial}{\\partial A_t} L_{ai}$ 的值，但这个变量还会额外储存一些项以作为求取 $\\frac{\\partial}{\\partial A_t} D_{ai}^{A_t}$ 的 Z-Vector 方程的等式右．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RHS = np.zeros((natm, 3, nvir, nocc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考察 $A_{ai, kl} D_{kl}^\\mathrm{MP2}$ 的导数\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial A_t} L_{ai} \\leftarrow\n",
    "A_{ai, kl} \\frac{\\partial}{\\partial A_t} D_{kl}^\\mathrm{MP2}\n",
    "+ A_{ai, kl}^{A_t} D_{kl}^\\mathrm{MP2}\n",
    "+ U_{pa}^{A_t} A_{pi, kl} D_{kl}^\\mathrm{MP2}\n",
    "+ U_{pi}^{A_t} A_{ap, kl} D_{kl}^\\mathrm{MP2}\n",
    "+ 2 A_{ai, pl} U_{pk}^{A_t} D_{kl}^\\mathrm{MP2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OO Part\n",
    "RHS += hfh.Ax0_Core(sv, so, so, so)(pdA_D_r_oo)\n",
    "RHS += hfh.Ax1_Core(sv, so, so, so)(np.array([[D_r_oo]]))[:, 0, :, 0]\n",
    "RHS += np.einsum(\"Atpa, pi -> Atai\", U_1[:, :, :, sv], hfh.Ax0_Core(sa, so, so, so)(D_r_oo))\n",
    "RHS += np.einsum(\"Atpi, ap -> Atai\", U_1[:, :, :, so], hfh.Ax0_Core(sv, sa, so, so)(D_r_oo))\n",
    "RHS += 2 * Ax0_Core(sv, so, sa, so)(np.einsum(\"Atpk, kl -> Atpl\", U_1[:, :, :, so], D_r_oo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考察 $A_{ai, kl} D_{bc}^\\mathrm{MP2}$ 的导数\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial A_t} L_{ai} \\leftarrow\n",
    "A_{ai, bc} (\\frac{\\partial}{\\partial A_t} D_{bc}^\\mathrm{MP2})\n",
    "+ A_{ai, bc}^{A_t} D_{bc}^\\mathrm{MP2}\n",
    "+ U_{pa}^{A_t} A_{pi, bc} D_{bc}^\\mathrm{MP2}\n",
    "+ U_{pi}^{A_t} A_{ap, bc} D_{bc}^\\mathrm{MP2}\n",
    "+ 2 A_{ai, pc} U_{pb}^{A_t} D_{bc}^\\mathrm{MP2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VV Part\n",
    "RHS += hfh.Ax0_Core(sv, so, sv, sv)(pdA_D_r_vv)\n",
    "RHS += hfh.Ax1_Core(sv, so, sv, sv)(np.array([[D_r_vv]]))[:, 0, :, 0]\n",
    "RHS += np.einsum(\"Atpa, pi -> Atai\", U_1[:, :, :, sv], hfh.Ax0_Core(sa, so, sv, sv)(D_r_vv))\n",
    "RHS += np.einsum(\"Atpi, ap -> Atai\", U_1[:, :, :, so], hfh.Ax0_Core(sv, sa, sv, sv)(D_r_vv))\n",
    "RHS += 2 * Ax0_Core(sv, so, sa, sv)(np.einsum(\"Atpb, bc -> Atpc\", U_1[:, :, :, sv], D_r_vv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考察 $- 4 T_{jk}^{ab} (ij|bk) + 4 T_{ij}^{bc} (ab|jc)$ 的导数\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial A_t} L_{ai} \\leftarrow\n",
    "- 4 (\\frac{\\partial}{\\partial A_t} T_{jk}^{ab}) (ij|bk)\n",
    "+ 4 (\\frac{\\partial}{\\partial A_t} T_{ij}^{bc}) (ab|jc)\n",
    "- 4 T_{jk}^{ab} \\frac{\\partial}{\\partial A_t} (ij|bk)\n",
    "+ 4 T_{ij}^{bc} \\frac{\\partial}{\\partial A_t} (ab|jc)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-pdm part\n",
    "RHS -= 4 * np.einsum(\"Atjakb, ijbk -> Atai\", pdA_T_iajb, g_mo[so, so, sv, so])\n",
    "RHS += 4 * np.einsum(\"Atibjc, abjc -> Atai\", pdA_T_iajb, g_mo[sv, sv, so, sv])\n",
    "RHS -= 4 * np.einsum(\"jakb, Atijbk -> Atai\", T_iajb, pdA_g_mo[:, :, so, so, sv, so])\n",
    "RHS += 4 * np.einsum(\"ibjc, Atabjc -> Atai\", T_iajb, pdA_g_mo[:, :, sv, sv, so, sv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就此，我们就求得了 Lagrangian 的导数部分了．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之所以需要求取 Lagrangian 导数，是因为我们可以对求取 $\\frac{\\partial}{\\partial A_t} D_{ai}^\\mathrm{MP2}$ 部分的 Z-Vector 进行再一次导数求取．如果原先的 Z-Vector 方程表示为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "(\\varepsilon_i - \\varepsilon_a) D_{ai}^\\mathrm{MP2} - A_{ai, bj} D_{bj}^\\mathrm{MP2} = L_{ai}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么对上述方程直接求导，并对等式进行非常初步的整理，就得到另一个 Z-Vector 方程了：\n",
    "\n",
    "$$\n",
    "(\\varepsilon_i - \\varepsilon_a) (\\frac{\\partial}{\\partial A_t} D_{ai}^\\mathrm{MP2}) - A_{ai, bj} (\\frac{\\partial}{\\partial A_t} D_{bj}^\\mathrm{MP2}) = \\frac{\\partial}{\\partial A_t} L_{ai} + (\\varepsilon_a^{A_t} - \\varepsilon_i^{A_t}) D_{ai}^\\mathrm{MP2} + (\\frac{\\partial}{\\partial A_t} A_{ai, bj}) D_{bj}^\\mathrm{MP2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述的 Z-Vector 方程的求解过程与以前的 Z-Vector 或 CP-HF 方程相同，只是求解对象是 $\\frac{\\partial}{\\partial A_t} D_{ai}^\\mathrm{MP2}$；同时，等式右除了 $\\frac{\\partial}{\\partial A_t} L_{ai}$ 之外，还有额外的两项．我们将这额外的两项放到等式右的 `RHS` 变量中．其中，$(\\varepsilon_a^{A_t} - \\varepsilon_i^{A_t}) D_{ai}^\\mathrm{MP2}$ 生成较为方便，但 $(\\frac{\\partial}{\\partial A_t} A_{ai, bj}) D_{bj}^\\mathrm{MP2}$ 的生成较为复杂：\n",
    "\n",
    "$$\n",
    "(\\frac{\\partial}{\\partial A_t} A_{ai, bj}) D_{bj}^\\mathrm{MP2} =\n",
    "A_{ai, bj}^{A_t} D_{bj}^\\mathrm{MP2}\n",
    "+ U_{pa}^{A_t} A_{pi, bj} D_{bj}^\\mathrm{MP2}\n",
    "+ U_{pi}^{A_t} A_{ap, bj} D_{bj}^\\mathrm{MP2}\n",
    "+ A_{ai, pj} U_{pb}^{A_t} D_{bj}^\\mathrm{MP2}\n",
    "+ A_{ai, bp} U_{pj}^{A_t} D_{bj}^\\mathrm{MP2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ea - ei) * Dai\n",
    "RHS += D_r[sv, so] * (ev_1[:, :, :, None] - eo_1[:, :, None, :])\n",
    "# OV Part\n",
    "RHS += hfh.Ax1_Core(sv, so, sv, so)(np.array([[D_r[sv, so]]]))[:, 0, :, 0]\n",
    "RHS += np.einsum(\"Atpa, pi -> Atai\", U_1[:, :, :, sv], hfh.Ax0_Core(sa, so, sv, so)(D_r_vo))\n",
    "RHS += np.einsum(\"Atpi, ap -> Atai\", U_1[:, :, :, so], hfh.Ax0_Core(sv, sa, sv, so)(D_r_vo))\n",
    "RHS += Ax0_Core(sv, so, sa, so)(np.einsum(\"Atpb, bj -> Atpj\", U_1[:, :, :, sv], D_r_vo))\n",
    "RHS += Ax0_Core(sv, so, sa, sv)(np.einsum(\"Atpj, bj -> Atpb\", U_1[:, :, :, so], D_r_vo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终，我们就可以通过 CP-HF 方程的流程，给出上述 Z-Vector 方程的结果 `pdA_D_r[:, :, sv, so]` $\\frac{\\partial}{\\partial A_t} D_{ai}^\\mathrm{MP2}$："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdA_D_r[:, :, sv, so] = scf.cphf.solve(Ax0_Core(sv, so, sv, so), e, hfh.mo_occ, RHS, max_cycle=100, tol=1e-13)[0].reshape(natm, 3, nvir, nocc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们指出，上述的代码的很多项其实是可以归并在一起的，特别是与 $D_{pq}^\\mathrm{MP2}$ 有关的项不需要进行分割便可一起代入算式计算．我们可以重写生成 $\\frac{\\partial}{\\partial A_t} D_{pq}^{A_t}$ 的代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdA_D_r = np.zeros((natm, 3, nmo, nmo))\n",
    "pdA_D_r[:, :, so, so] -= 2 * np.einsum(\"iakb, Atjakb -> Atij\", T_iajb, pdA_t_iajb)\n",
    "pdA_D_r[:, :, sv, sv] += 2 * np.einsum(\"iajc, Atibjc -> Atab\", T_iajb, pdA_t_iajb)\n",
    "pdA_D_r[:, :, so, so] -= 2 * np.einsum(\"Atiakb, jakb -> Atij\", pdA_T_iajb, t_iajb)\n",
    "pdA_D_r[:, :, sv, sv] += 2 * np.einsum(\"Atiajc, ibjc -> Atab\", pdA_T_iajb, t_iajb)\n",
    "\n",
    "RHS = np.zeros((natm, 3, nvir, nocc))\n",
    "# D_r Part\n",
    "RHS += hfh.Ax0_Core(sv, so, sa, sa)(pdA_D_r)\n",
    "RHS += hfh.Ax1_Core(sv, so, sa, sa)(np.array([[D_r]]))[:, 0, :, 0]\n",
    "RHS += np.einsum(\"Atpa, pi -> Atai\", U_1[:, :, :, sv], hfh.Ax0_Core(sa, so, sa, sa)(D_r))\n",
    "RHS += np.einsum(\"Atpi, ap -> Atai\", U_1[:, :, :, so], hfh.Ax0_Core(sv, sa, sa, sa)(D_r))\n",
    "RHS += Ax0_Core(sv, so, sa, sa)(np.einsum(\"Atmp, pq -> Atmq\", U_1, D_r))\n",
    "RHS += Ax0_Core(sv, so, sa, sa)(np.einsum(\"Atmq, pq -> Atpm\", U_1, D_r))\n",
    "# (ea - ei) * Dai\n",
    "RHS += D_r[sv, so] * (ev_1[:, :, :, None] - eo_1[:, :, None, :])\n",
    "# 2-pdm part\n",
    "RHS -= 4 * np.einsum(\"Atjakb, ijbk -> Atai\", pdA_T_iajb, g_mo[so, so, sv, so])\n",
    "RHS += 4 * np.einsum(\"Atibjc, abjc -> Atai\", pdA_T_iajb, g_mo[sv, sv, so, sv])\n",
    "RHS -= 4 * np.einsum(\"jakb, Atijbk -> Atai\", T_iajb, pdA_g_mo[:, :, so, so, sv, so])\n",
    "RHS += 4 * np.einsum(\"ibjc, Atabjc -> Atai\", T_iajb, pdA_g_mo[:, :, sv, sv, so, sv])\n",
    "\n",
    "# Z-Vector\n",
    "pdA_D_r[:, :, sv, so] = scf.cphf.solve(Ax0_Core(sv, so, sv, so), e, hfh.mo_occ, RHS, max_cycle=100, tol=1e-13)[0].reshape(natm, 3, nvir, nocc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读者可以自行验证简化后的代码所生成的 `pdA_D_r` 与简化前的代码是完全相同的．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三贡献项 $(\\frac{\\partial}{\\partial B_s} D_{pq}^\\mathrm{MP2}) F_{pq}^{A_t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然得到了 $\\frac{\\partial}{\\partial B_s} D_{pq}^\\mathrm{MP2}$，那么第三贡献项 `hess_mp2_unsafe_contrib3` 的求取几乎是显然的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_mp2_unsafe_contrib3 = np.einsum(\"Bspq, Atpq -> ABts\", pdA_D_r, F_1_mo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四贡献项 $(\\frac{\\partial}{\\partial B_s} W_{pq}^\\mathrm{MP2}) S_{pq}^{A_t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一个贡献项要求对 $W_{pq}^\\mathrm{MP2}$ 进行求导．在有了轨道能导数、分子轨道双电子积分导数的情况下，这是相对来说常规性的工作，即对每一项而言，直接作全导数即可．必要的全导数我们早已生成，因此一项一项仔细来便可．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一部分 (Aikens, 181-183)\n",
    "\n",
    "\\begin{align}\n",
    "W_{ij}^\\mathrm{MP2} [\\mathrm{I}] &= - 2 T_{ik}^{ab} (ja|kb) \\\\\n",
    "W_{ab}^\\mathrm{MP2} [\\mathrm{I}] &= - 2 T_{ij}^{ac} (ib|jc) \\\\\n",
    "W_{ai}^\\mathrm{MP2} [\\mathrm{I}] &= - 4 T_{jk}^{ab} (ij|bk) \\\\\n",
    "W_{ia}^\\mathrm{MP2} [\\mathrm{I}] &= 0\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdA_D_WI = np.zeros((natm, 3, nmo, nmo))\n",
    "pdA_D_WI[:, :, so, so] -= 2 * np.einsum(\"Atiakb, jakb -> Atij\", pdA_T_iajb, g_mo[so, sv, so, sv])\n",
    "pdA_D_WI[:, :, sv, sv] -= 2 * np.einsum(\"Atiajc, ibjc -> Atab\", pdA_T_iajb, g_mo[so, sv, so, sv])\n",
    "pdA_D_WI[:, :, sv, so] -= 4 * np.einsum(\"Atjakb, ijbk -> Atai\", pdA_T_iajb, g_mo[so, so, sv, so])\n",
    "pdA_D_WI[:, :, so, so] -= 2 * np.einsum(\"iakb, Atjakb -> Atij\", T_iajb, pdA_g_mo[:, :, so, sv, so, sv])\n",
    "pdA_D_WI[:, :, sv, sv] -= 2 * np.einsum(\"iajc, Atibjc -> Atab\", T_iajb, pdA_g_mo[:, :, so, sv, so, sv])\n",
    "pdA_D_WI[:, :, sv, so] -= 4 * np.einsum(\"jakb, Atijbk -> Atai\", T_iajb, pdA_g_mo[:, :, so, so, sv, so])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二部分 (Aikens, 184-186)\n",
    "\n",
    "\\begin{align}\n",
    "W_{ij}^\\mathrm{MP2} [\\mathrm{II}] &= - \\frac{1}{2} D_{ij}^\\mathrm{MP2} (\\varepsilon_i + \\varepsilon_j) \\\\\n",
    "W_{ab}^\\mathrm{MP2} [\\mathrm{II}] &= - \\frac{1}{2} D_{ab}^\\mathrm{MP2} (\\varepsilon_a + \\varepsilon_b) \\\\\n",
    "W_{ai}^\\mathrm{MP2} [\\mathrm{II}] &= - D_{ai}^\\mathrm{MP2} \\varepsilon_i \\\\\n",
    "W_{ia}^\\mathrm{MP2} [\\mathrm{II}] &= 0\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdA_D_WII = np.zeros((natm, 3, nmo, nmo))\n",
    "pdA_D_WII[:, :, so, so] -= 0.5 * pdA_D_r[:, :, so, so] * (eo[:, None] + eo[None, :])\n",
    "pdA_D_WII[:, :, sv, sv] -= 0.5 * pdA_D_r[:, :, sv, sv] * (ev[:, None] + ev[None, :])\n",
    "pdA_D_WII[:, :, sv, so] -= pdA_D_r[:, :, sv, so] * eo\n",
    "pdA_D_WII[:, :, so, so] -= 0.5 * D_r[so, so] * (eo_1[:, :, :, None] + eo_1[:, :, None, :])\n",
    "pdA_D_WII[:, :, sv, sv] -= 0.5 * D_r[sv, sv] * (ev_1[:, :, :, None] + ev_1[:, :, None, :])\n",
    "pdA_D_WII[:, :, sv, so] -= np.einsum(\"ai, Ati -> Atai\", D_r[sv, so], eo_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三部分 (Aikens, 187)\n",
    "\n",
    "$$\n",
    "W_{ij}^\\mathrm{MP2} [\\mathrm{III}] = - \\frac{1}{2} A_{ij, pq} D_{pq}^\\mathrm{MP2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一份梯度相对来说比较麻烦，但我们在推导 Lagrangian 导数时，已经对如何求取 $\\frac{\\partial}{\\partial A_t} A_{ij, pq}$ 项的表达式已经有所了解了．因此这里就不再详述．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdA_D_WIII = np.zeros((natm, 3, nmo, nmo))\n",
    "pdA_D_WIII[:, :, so, so] -= 0.5 * hfh.Ax0_Core(so, so, sa, sa)(pdA_D_r)\n",
    "pdA_D_WIII[:, :, so, so] -= 0.5 * hfh.Ax1_Core(so, so, sa, sa)(np.array([[D_r]]))[:, 0, :, 0]\n",
    "pdA_D_WIII[:, :, so, so] -= 0.5 * np.einsum(\"Atmi, mj -> Atij\", U_1[:, :, :, so], hfh.Ax0_Core(sa, so, sa, sa)(D_r))\n",
    "pdA_D_WIII[:, :, so, so] -= 0.5 * np.einsum(\"Atmj, im -> Atij\", U_1[:, :, :, so], hfh.Ax0_Core(so, sa, sa, sa)(D_r))\n",
    "pdA_D_WIII[:, :, so, so] -= 0.5 * Ax0_Core(so, so, sa, sa)(np.einsum(\"Atmp, pq -> Atmq\", U_1, D_r))\n",
    "pdA_D_WIII[:, :, so, so] -= 0.5 * Ax0_Core(so, so, sa, sa)(np.einsum(\"Atmq, pq -> Atmp\", U_1, D_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终，我们将这三部分贡献相加，就得到了 `pdA_D_W` $\\frac{\\partial}{\\partial A_t} W_{pq}^\\mathrm{MP2}$．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdA_D_W = pdA_D_WI + pdA_D_WII + pdA_D_WIII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么第 4 贡献项 `hess_mp2_unsafe_contrib4` 就表示为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_mp2_unsafe_contrib4 = np.einsum(\"Bspq, Atpq -> ABts\", pdA_D_W, S_1_mo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贡献总和"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们简单地将所有的六项贡献加和，就得到了 MP2 相关能的总二阶梯度 $E_\\mathrm{elec}^{\\mathrm{MP2}, A_t B_s}$："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hess_mp2_unsafe = (\n",
    "    + hess_mp2_unsafe_contrib1\n",
    "    + hess_mp2_unsafe_contrib2\n",
    "    + hess_mp2_unsafe_contrib3\n",
    "    + hess_mp2_unsafe_contrib4\n",
    "    + hess_mp2_unsafe_contrib5_6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(hess_mp2_unsafe, hess_mp2_unsafe.swapaxes(0, 1).swapaxes(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.80147912314366e-08\n",
      "-6.048360039201395e-08\n"
     ]
    }
   ],
   "source": [
    "print((hess_mp2_unsafe - hess_mp2_ref).max())\n",
    "print((hess_mp2_unsafe - hess_mp2_ref).min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逆向 Z-Vector 过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这份文档的最末，我们指出事实上，我们不需要真正地获得 $\\frac{\\partial}{\\partial A_t} D_{ai}^\\mathrm{MP2}$，也因此应当可以避免一次等同于求解一阶 U 矩阵计算量的 Z-Vector 过程．这称为所谓的“逆向 Z-Vector 过程”，由 Cammi et al. TCA 2004 文章的最末提出．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逆向 Z-Vector 过程的思路其实很简单．我们用简化的记号来说明问题．如果现在，我们记 $\\mathbf{P} = \\frac{\\partial}{\\partial A_t} D_{ai}^\\mathrm{MP2}$，并且记生成 $\\frac{\\partial}{\\partial A_t} D_{ai}^\\mathrm{MP2}$ 的 Z-Vector 方程为\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{P} = \\mathbf{L}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而如果我们将所有因 $\\frac{\\partial}{\\partial A_t} D_{ai}^\\mathrm{MP2}$ 对 $E_\\mathrm{elec}^{\\mathrm{MP2}, A_t B_s}$ 产生贡献的项记为\n",
    "\n",
    "$$\n",
    "E_\\mathrm{elec}^{\\mathrm{MP2}, A_t B_s} \\leftarrow \\mathbf{P} \\mathbf{Q}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么\n",
    "\n",
    "$$\n",
    "\\mathbf{P} \\mathbf{Q} = \\mathbf{A}^{-1} \\mathbf{Q} \\mathbf{L}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "凑巧的是，如果我们写出 $\\mathbf{Q}$ 的详细结果，我们会发现这恰好是解一阶 U 矩阵的 CP-HF 方程等式右：\n",
    "\n",
    "$$\n",
    "\\mathbf{Q} : F_{ai}^{A_t} - S_{ai}^{A_t} \\varepsilon_i - \\frac{1}{2} A_{ai, kl}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，我们可以将 $\\mathbf{A}^{-1} \\mathbf{Q}$ 看作一阶 U 矩阵 $\\mathbf{U}$，因此我们真正需要求取的部分实际上即是 \n",
    "\n",
    "$$\n",
    "E_\\mathrm{elec}^{\\mathrm{MP2}, A_t B_s} \\leftarrow \\mathbf{U} \\mathbf{L}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实际编写代码的过程中，我们可以这么做：只生成占据-占据与非占-非占部分的 `pdA_D_r`，而将非占-占据部分空出；随后将所有与非占-占据有关的项全部剔除 (包括第三贡献项、第四贡献项中 $\\frac{\\partial}{\\partial A_t} W_ai[\\mathrm{II}]$ 和 $\\frac{\\partial}{\\partial A_t} W_{ij}[\\mathrm{III}]$ 的一部分)，反补上 `RHS` 与 `U_1_vo` $U_{ai}^{A_t}$ 的张量缩并即可．代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdA_D_r = np.zeros((natm, 3, nmo, nmo))\n",
    "pdA_D_r[:, :, so, so] -= 2 * np.einsum(\"iakb, Atjakb -> Atij\", T_iajb, pdA_t_iajb)\n",
    "pdA_D_r[:, :, sv, sv] += 2 * np.einsum(\"iajc, Atibjc -> Atab\", T_iajb, pdA_t_iajb)\n",
    "pdA_D_r[:, :, so, so] -= 2 * np.einsum(\"Atiakb, jakb -> Atij\", pdA_T_iajb, t_iajb)\n",
    "pdA_D_r[:, :, sv, sv] += 2 * np.einsum(\"Atiajc, ibjc -> Atab\", pdA_T_iajb, t_iajb)\n",
    "\n",
    "RHS = np.zeros((natm, 3, nvir, nocc))\n",
    "# D_r Part\n",
    "RHS += hfh.Ax0_Core(sv, so, sa, sa)(pdA_D_r)\n",
    "RHS += hfh.Ax1_Core(sv, so, sa, sa)(np.array([[D_r]]))[:, 0, :, 0]\n",
    "RHS += np.einsum(\"Atpa, pi -> Atai\", U_1[:, :, :, sv], hfh.Ax0_Core(sa, so, sa, sa)(D_r))\n",
    "RHS += np.einsum(\"Atpi, ap -> Atai\", U_1[:, :, :, so], hfh.Ax0_Core(sv, sa, sa, sa)(D_r))\n",
    "RHS += Ax0_Core(sv, so, sa, sa)(np.einsum(\"Atmp, pq -> Atmq\", U_1, D_r))\n",
    "RHS += Ax0_Core(sv, so, sa, sa)(np.einsum(\"Atmq, pq -> Atpm\", U_1, D_r))\n",
    "# (ea - ei) * Dai\n",
    "RHS += D_r[sv, so] * (ev_1[:, :, :, None] - eo_1[:, :, None, :])\n",
    "# 2-pdm part\n",
    "RHS -= 4 * np.einsum(\"Atjakb, ijbk -> Atai\", pdA_T_iajb, g_mo[so, so, sv, so])\n",
    "RHS += 4 * np.einsum(\"Atibjc, abjc -> Atai\", pdA_T_iajb, g_mo[sv, sv, so, sv])\n",
    "RHS -= 4 * np.einsum(\"jakb, Atijbk -> Atai\", T_iajb, pdA_g_mo[:, :, so, so, sv, so])\n",
    "RHS += 4 * np.einsum(\"ibjc, Atabjc -> Atai\", T_iajb, pdA_g_mo[:, :, sv, sv, so, sv])\n",
    "\n",
    "# Do not generate pdA_D_r[:, :, sv, so] here. Leave zeros there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o-o and v-v part contribution of original contrib3\n",
    "# code is the same, however result value is different compared with contrib3\n",
    "hess_mp2_unsafe_contrib3_4 = np.einsum(\"Bspq, Atpq -> ABts\", pdA_D_r, F_1_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WI part is the same as before\n",
    "pdA_D_W = np.zeros((natm, 3, nmo, nmo))\n",
    "pdA_D_W[:, :, so, so] -= 2 * np.einsum(\"Atiakb, jakb -> Atij\", pdA_T_iajb, g_mo[so, sv, so, sv])\n",
    "pdA_D_W[:, :, sv, sv] -= 2 * np.einsum(\"Atiajc, ibjc -> Atab\", pdA_T_iajb, g_mo[so, sv, so, sv])\n",
    "pdA_D_W[:, :, sv, so] -= 4 * np.einsum(\"Atjakb, ijbk -> Atai\", pdA_T_iajb, g_mo[so, so, sv, so])\n",
    "pdA_D_W[:, :, so, so] -= 2 * np.einsum(\"iakb, Atjakb -> Atij\", T_iajb, pdA_g_mo[:, :, so, sv, so, sv])\n",
    "pdA_D_W[:, :, sv, sv] -= 2 * np.einsum(\"iajc, Atibjc -> Atab\", T_iajb, pdA_g_mo[:, :, so, sv, so, sv])\n",
    "pdA_D_W[:, :, sv, so] -= 4 * np.einsum(\"jakb, Atijbk -> Atai\", T_iajb, pdA_g_mo[:, :, so, so, sv, so])\n",
    "\n",
    "# WII's pdA_D_r[:, :, sv, so] contribution is zero\n",
    "pdA_D_W[:, :, so, so] -= 0.5 * pdA_D_r[:, :, so, so] * (eo[:, None] + eo[None, :])\n",
    "pdA_D_W[:, :, sv, sv] -= 0.5 * pdA_D_r[:, :, sv, sv] * (ev[:, None] + ev[None, :])\n",
    "# pdA_D_W[:, :, sv, so] -= pdA_D_r[:, :, sv, so] * eo  # this code only returns zero value\n",
    "pdA_D_W[:, :, so, so] -= 0.5 * D_r[so, so] * (eo_1[:, :, :, None] + eo_1[:, :, None, :])\n",
    "pdA_D_W[:, :, sv, sv] -= 0.5 * D_r[sv, sv] * (ev_1[:, :, :, None] + ev_1[:, :, None, :])\n",
    "pdA_D_W[:, :, sv, so] -= np.einsum(\"ai, Ati -> Atai\", D_r[sv, so], eo_1)\n",
    "\n",
    "# WIII's code is the same as before, but result value is different compared with that before\n",
    "pdA_D_W[:, :, so, so] -= 0.5 * hfh.Ax0_Core(so, so, sa, sa)(pdA_D_r)\n",
    "pdA_D_W[:, :, so, so] -= 0.5 * hfh.Ax1_Core(so, so, sa, sa)(np.array([[D_r]]))[:, 0, :, 0]\n",
    "pdA_D_W[:, :, so, so] -= 0.5 * np.einsum(\"Atmi, mj -> Atij\", U_1[:, :, :, so], hfh.Ax0_Core(sa, so, sa, sa)(D_r))\n",
    "pdA_D_W[:, :, so, so] -= 0.5 * np.einsum(\"Atmj, im -> Atij\", U_1[:, :, :, so], hfh.Ax0_Core(so, sa, sa, sa)(D_r))\n",
    "pdA_D_W[:, :, so, so] -= 0.5 * Ax0_Core(so, so, sa, sa)(np.einsum(\"Atmp, pq -> Atmq\", U_1, D_r))\n",
    "pdA_D_W[:, :, so, so] -= 0.5 * Ax0_Core(so, so, sa, sa)(np.einsum(\"Atmq, pq -> Atmp\", U_1, D_r))\n",
    "\n",
    "# part of contribution of original contrib4\n",
    "hess_mp2_unsafe_contrib3_4 += np.einsum(\"Bspq, Atpq -> ABts\", pdA_D_W, S_1_mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, add RHS * U_1_vo\n",
    "hess_mp2_unsafe_contrib3_4 += np.einsum(\"Atai, Bsai -> ABts\", U_1_vo, RHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(\n",
    "    hess_mp2_unsafe_contrib3_4,\n",
    "    hess_mp2_unsafe_contrib3 + hess_mp2_unsafe_contrib4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hess_mp2_byReverseZvect = (\n",
    "    + hess_mp2_unsafe_contrib1\n",
    "    + hess_mp2_unsafe_contrib2\n",
    "    + hess_mp2_unsafe_contrib3_4\n",
    "    + hess_mp2_unsafe_contrib5_6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(hess_mp2_byReverseZvect, hess_mp2_byReverseZvect.swapaxes(0, 1).swapaxes(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.801609871333713e-08\n",
      "-6.048682157921981e-08\n"
     ]
    }
   ],
   "source": [
    "print((hess_mp2_byReverseZvect - hess_mp2_ref).max())\n",
    "print((hess_mp2_byReverseZvect - hess_mp2_ref).min())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
